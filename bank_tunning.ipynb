{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b39b51d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-12T05:44:47.704610Z",
     "start_time": "2024-10-12T05:44:47.695637Z"
    }
   },
   "outputs": [],
   "source": [
    "# import libraries\n",
    "\n",
    "# to handle the data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# to visualize the dataset\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# to preprocess the data\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder    \n",
    "\n",
    "# machine learning\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "# model\n",
    "import lightgbm as lgb\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# evaluation\n",
    "from sklearn.metrics import matthews_corrcoef as MCC\n",
    "from sklearn.metrics import roc_curve, auc, confusion_matrix\n",
    "\n",
    "# max columns \n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# hide warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# tun parameters\n",
    "import optuna\n",
    "from pyswarm import pso\n",
    "\n",
    "# sampling\n",
    "from imblearn.combine import SMOTETomek\n",
    "\n",
    "from collections import Counter\n",
    "from math import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea7ed0ae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-12T05:44:48.568327Z",
     "start_time": "2024-10-12T05:44:48.497035Z"
    }
   },
   "outputs": [],
   "source": [
    "# train data\n",
    "df = pd.read_csv(\"bank-full.csv\",sep = ';')\n",
    "df = shuffle(df,random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30656f1a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-12T05:44:49.386010Z",
     "start_time": "2024-10-12T05:44:49.366970Z"
    }
   },
   "outputs": [],
   "source": [
    "def label_binary(df_train,df_test):\n",
    "    # 'default','housing','loan' - binary\n",
    "    # no = 0, yes =1\n",
    "    label_encoder = LabelEncoder()\n",
    "    object_cols = ['default','housing','loan','y']\n",
    "    for col in object_cols:\n",
    "        df_train[col] = label_encoder.fit_transform(df_train[col])\n",
    "        df_test[col] = label_encoder.transform(df_test[col])\n",
    "    return df_train,df_test\n",
    "\n",
    "def onehot(df):\n",
    "    cat_cols = ['marital','education','contact','poutcome','month','job']\n",
    "    #onehotEncoding\n",
    "    try:\n",
    "        df=pd.get_dummies(df,columns=cat_cols)\n",
    "        return df\n",
    "    except:\n",
    "        print('there is no cat_cols in the df')\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ff71f2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-12T05:45:03.365707Z",
     "start_time": "2024-10-12T05:44:50.541994Z"
    }
   },
   "outputs": [],
   "source": [
    "X_kos_folds = []\n",
    "y_kos_folds = []\n",
    "df_test_folds = []\n",
    "feat_cols_folds = []\n",
    "k = 5\n",
    "for i in range(k):\n",
    "    \n",
    "    # 5 folds split\n",
    "    n = df.shape[0]//5 # split point\n",
    "    df_train = pd.concat([df[:i*n],df[(i+1)*n:]])\n",
    "    df_test = df[i*n:(i+1)*n]\n",
    "\n",
    "    # process numerical variables\n",
    "    numeirc_cols = ['age','balance','duration','campaign','pdays','previous','day']\n",
    "    for col in numeirc_cols:\n",
    "        sc = MinMaxScaler()\n",
    "        df_train[col+\"_scaled\"] = sc.fit_transform(df_train[[col]])\n",
    "        df_test[col+\"_scaled\"] = sc.transform(df_test[[col]])\n",
    "    \n",
    "    # process categorical variables\n",
    "    df_train,df_test = label_binary(df_train,df_test)\n",
    "    df_train = onehot(df_train)\n",
    "    df_test = onehot(df_test)\n",
    "    \n",
    "    # Selecting Columns FOr use \n",
    "    feat_cols=df_train.columns.drop(['y'])\n",
    "    feat_cols=feat_cols.drop(numeirc_cols)\n",
    "    \n",
    "    # choose predictor and responser\n",
    "    X=df_train[feat_cols]\n",
    "    y=df_train['y']\n",
    "    \n",
    "    # combining sampling\n",
    "    kos = SMOTETomek(random_state=0)\n",
    "    X_kos, y_kos = kos.fit_resample(X, y)\n",
    "    print(f'The Shape Of X is {X_kos.shape}')\n",
    "    print(f'The Shape Of y is {y_kos.shape}')\n",
    "    \n",
    "    X_kos_folds.append(X_kos)\n",
    "    y_kos_folds.append(y_kos)\n",
    "    df_test_folds.append(df_test)\n",
    "    feat_cols_folds.append(feat_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e34a612a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-12T05:46:16.596591Z",
     "start_time": "2024-10-12T05:45:07.635018Z"
    }
   },
   "outputs": [],
   "source": [
    "# LightGBM Parameters adjusting\n",
    "def objective(trial):\n",
    "    Params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators',800, 1200),\n",
    "        'num_leaves': trial.suggest_int('num_leaves',100,300),\n",
    "        'learning_rate': trial.suggest_categorical('learning_rate',[0.01,0.005,0.015,0.02,0.025]),\n",
    "        'max_depth': 4trial.suggest_int('max_depth',20,80),\n",
    "        'min_child_weight': trial.suggest_categorical('min_child_weight',[0.001,0.0001,0.00001,0.000001,0.0000001,0]),\n",
    "        'min_child_samples': trial.suggest_int('min_child_samples',5, 32),\n",
    "        'subsample': trial.suggest_categorical('subsample',[0.8,0.9,1]),\n",
    "        'colsample_bytree': trial.suggest_categorical('colsample_bytree',[0.8,0.9,1]),\n",
    "        'verbose':-1\n",
    "    }\n",
    "    \n",
    "    lgb_mcc = []\n",
    "    for i in range(k):\n",
    "        X_kos = X_kos_folds[i]\n",
    "        y_kos = y_kos_folds[i]\n",
    "        df_test = df_test_folds[i]\n",
    "        feat_cols = feat_cols_folds[i]\n",
    "\n",
    "        # train the model\n",
    "        lgb_model = lgb.LGBMClassifier(**Params)\n",
    "        lgb_model.fit(X_kos,y_kos)\n",
    "        test_predictions = lgb_model.predict_proba(df_test[feat_cols])[:, 1]\n",
    "        test_labels = [i >= 0.5 for i in test_predictions]\n",
    "        mcc = MCC(df_test['y'], test_labels)\n",
    "        lgb_mcc.append(mcc)\n",
    "\n",
    "    return sum(lgb_mcc)/5\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=50,show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "641365fc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-12T05:46:19.938179Z",
     "start_time": "2024-10-12T05:46:18.923299Z"
    }
   },
   "outputs": [],
   "source": [
    "best_params = study.best_params\n",
    "print(f\"Best Params: {best_params}\")\n",
    "optuna.visualization.plot_param_importances(study).show()\n",
    "optuna.visualization.plot_optimization_history(study).show()\n",
    "optuna.visualization.plot_slice(study).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d8656e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-12T05:56:25.352985Z",
     "start_time": "2024-10-12T05:56:23.003738Z"
    }
   },
   "outputs": [],
   "source": [
    "# CatBoostClassifier\n",
    "def objective(trial):\n",
    "    Params = {\n",
    "        'eval_metric':'AUC',\n",
    "        'iterations': 1000,\n",
    "        'depth': trial.suggest_int('depth',1,16),\n",
    "        'learning_rate': trial.suggest_categorical('learning_rate',[0.005 * i for i in range(1,21)]),\n",
    "        'subsample': trial.suggest_categorical('subsample',[0.8,0.9,1]),\n",
    "        'rsm': trial.suggest_categorical('rsm',[0.01*i for i in range(1,21)]),\n",
    "        'verbose': False\n",
    "             }\n",
    "    \n",
    "    cat_mcc = []\n",
    "    for i in range(k):\n",
    "        X_kos = X_kos_folds[i]\n",
    "        y_kos = y_kos_folds[i]\n",
    "        df_test = df_test_folds[i]\n",
    "        feat_cols = feat_cols_folds[i]\n",
    "        \n",
    "        # Cat_features\n",
    "        cat_features = np.where(X_kos.dtypes != np.float64)[0]\n",
    "\n",
    "        # Train the model on the entire dataset\n",
    "        cat_model = CatBoostClassifier(**Params)\n",
    "        train_pool = Pool(X_kos, y_kos, cat_features=cat_features)\n",
    "        cat_model.fit(train_pool)\n",
    "\n",
    "        # Make predictions on the test set\n",
    "        test_pool = Pool(df_test[feat_cols], cat_features=cat_features)\n",
    "        test_predictions = cat_model.predict_proba(test_pool)[:, 1]\n",
    "        test_labels = [i >= 0.5 for i in test_predictions]\n",
    "        mcc = MCC(df_test['y'], test_labels)\n",
    "        cat_mcc.append(mcc)\n",
    "\n",
    "        # train the model\n",
    "        cat_model = CatBoostClassifier(**Params)\n",
    "        cat_model.fit(X_kos,y_kos)\n",
    "        test_predictions = cat_model.predict_proba(df_test[feat_cols])[:, 1]\n",
    "        test_labels = [i >= 0.5 for i in test_predictions]\n",
    "        mcc = MCC(df_test['y'], test_labels)\n",
    "        cat_mcc.append(mcc)\n",
    "\n",
    "    return sum(cat_mcc)/5\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=50,show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3b0559",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = study.best_params\n",
    "print(f\"Best Params: {best_params}\")\n",
    "optuna.visualization.plot_param_importances(study).show()\n",
    "optuna.visualization.plot_optimization_history(study).show()\n",
    "optuna.visualization.plot_slice(study).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d4672e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost Parameters\n",
    "def objective(trial):\n",
    "    Params = {\n",
    "        'n_estimators': ttrial.suggest_int('n_estimators',10,1000),\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 100, 1000),\n",
    "        'learning_rate': trial.suggest_categorical('learning_rate',[0.005 * i for i in range(1,21)]),\n",
    "        'max_depth':trial.suggest_int('max_depth',10,50),\n",
    "        'min_child_weight': trial.suggest_categorical('min_child_weight',[0.01,0.001,0.0001,0.00001,0.000001,0]),\n",
    "        'min_child_samples': trial.suggest_int('min_child_samples',10, 50),\n",
    "        'subsample': trial.suggest_categorical('subsample',[0.8,0.9,1]),\n",
    "        'colsample_bytree': trial.suggest_categorical('colsample_bytree',[0.8,0.9,1]),\n",
    "        'objective': 'binary:logistic',\n",
    "        'eval_metric': 'auc'\n",
    "             }\n",
    "    \n",
    "    xgb_mcc = []\n",
    "    for i in range(k):\n",
    "        X_kos = X_kos_folds[i]\n",
    "        y_kos = y_kos_folds[i]\n",
    "        df_test = df_test_folds[i]\n",
    "        feat_cols = feat_cols_folds[i]\n",
    "\n",
    "        # train the model\n",
    "        xgb_model = xgb.XGBClassifier(**Params)\n",
    "        xgb_model.fit(X_kos,y_kos)\n",
    "        test_predictions = xgb_model.predict_proba(df_test[feat_cols])[:, 1]\n",
    "        test_labels = [i >= 0.5 for i in test_predictions]\n",
    "        mcc = MCC(df_test['y'], test_labels)\n",
    "        xgb_mcc.append(mcc)\n",
    "\n",
    "    return sum(xgb_mcc)/5\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=50,show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97010e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = study.best_params\n",
    "print(f\"Best Params: {best_params}\")\n",
    "optuna.visualization.plot_param_importances(study).show()\n",
    "optuna.visualization.plot_optimization_history(study).show()\n",
    "optuna.visualization.plot_slice(study).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9689f5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "def objective(trial):\n",
    "    Params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators',10,1000),\n",
    "        'max_features': trial.suggest_int('num_leaves', 5, 32),\n",
    "             }\n",
    "\n",
    "    rf_mcc = []\n",
    "    for i in range(k):\n",
    "        X_kos = X_kos_folds[i]\n",
    "        y_kos = y_kos_folds[i]\n",
    "        df_test = df_test_folds[i]\n",
    "        feat_cols = feat_cols_folds[i]\n",
    "\n",
    "        # train the model\n",
    "        rf_model = RandomForestClassifier(**Params)\n",
    "        rf_model.fit(X_kos,y_kos)\n",
    "        test_predictions = rf_model.predict_proba(df_test[feat_cols])[:, 1]\n",
    "        test_labels = [i >= 0.5 for i in test_predictions]\n",
    "        mcc = MCC(df_test['y'], test_labels)\n",
    "        rf_mcc.append(mcc)\n",
    "\n",
    "    return sum(rf_mcc)/5\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=50,show_progress_bar=True)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06480f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = study.best_params\n",
    "print(f\"Best Params: {best_params}\")\n",
    "optuna.visualization.plot_param_importances(study).show()\n",
    "optuna.visualization.plot_optimization_history(study).show()\n",
    "optuna.visualization.plot_slice(study).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b7eac9e",
   "metadata": {},
   "source": [
    "---\n",
    "## Catboost with PSO and its performance visualization & feature importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd912154b1e6923",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-12T06:09:20.177791Z",
     "start_time": "2024-10-12T05:58:37.082622Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define the MCC objective function for PSO\n",
    "def objective(params):\n",
    "    depth, learning_rate, subsample, rsm = params\n",
    "    cat_params = {\n",
    "        'eval_metric':'AUC',\n",
    "        'iterations': 1000,\n",
    "        'depth': int(depth),  # depth should be an integer\n",
    "        'learning_rate': learning_rate,\n",
    "        'subsample': subsample,\n",
    "        'rsm': rsm,\n",
    "        'verbose': False\n",
    "    }\n",
    "\n",
    "    cat_mcc = []\n",
    "    for i in range(k):\n",
    "        X_kos = X_kos_folds[i]\n",
    "        y_kos = y_kos_folds[i]\n",
    "        df_test = df_test_folds[i]\n",
    "        feat_cols = feat_cols_folds[i]\n",
    "\n",
    "        # Cat_features\n",
    "        cat_features = np.where(X_kos.dtypes != np.float64)[0]\n",
    "\n",
    "        # Train the model\n",
    "        cat_model = CatBoostClassifier(**cat_params)\n",
    "        train_pool = Pool(X_kos, y_kos, cat_features=cat_features)\n",
    "        cat_model.fit(train_pool)\n",
    "\n",
    "        # Make predictions on the test set\n",
    "        test_pool = Pool(df_test[feat_cols], cat_features=cat_features)\n",
    "        test_predictions = cat_model.predict_proba(test_pool)[:, 1]\n",
    "        test_labels = [i >= 0.5 for i in test_predictions]\n",
    "\n",
    "        # Calculate MCC\n",
    "        mcc = MCC(df_test['y'], test_labels)\n",
    "        cat_mcc.append(mcc)\n",
    "\n",
    "    return -sum(cat_mcc)/k  # PSO minimizes, so we negate MCC for maximization\n",
    "\n",
    "# Parameter bounds: [min, max] for depth, learning_rate, subsample, and rsm\n",
    "lb = [1, 0.005, 0.8, 0.01]  # lower bounds\n",
    "ub = [16, 0.1, 1.0, 0.2]    # upper bounds\n",
    "\n",
    "# Run PSO to optimize CatBoost parameters\n",
    "best_params, best_mcc = pso(objective, lb, ub, swarmsize=1, maxiter=10,debug=True)\n",
    "\n",
    "print(f\"Best parameters: {best_params}\")\n",
    "print(f\"Best MCC: {-best_mcc}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b9649da5d89e55e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-12T06:59:31.365291Z",
     "start_time": "2024-10-12T06:58:38.930702Z"
    }
   },
   "outputs": [],
   "source": [
    "# Visualization: ROC curve, confusion matrix, feature importance, AUC score change\n",
    "def full_visualization(best_params):\n",
    "    cat_params = {\n",
    "        'eval_metric': 'AUC',\n",
    "        'iterations': 1000,\n",
    "        'depth': int(best_params[0]),\n",
    "        'learning_rate': best_params[1],\n",
    "        'subsample': best_params[2],\n",
    "        'rsm': best_params[3],\n",
    "        'verbose': False\n",
    "    }\n",
    "\n",
    "    mean_fpr = np.linspace(0, 1, 100)\n",
    "    tprs = []\n",
    "    aucs = []\n",
    "    feature_importances = None\n",
    "    plt.figure(figsize=(14, 12))\n",
    "\n",
    "    # 1. Plot ROC curves and collect AUC scores\n",
    "    plt.subplot(2, 2, 1)\n",
    "    for i in range(k):\n",
    "        X_kos = X_kos_folds[i]\n",
    "        y_kos = y_kos_folds[i]\n",
    "        df_test = df_test_folds[i]\n",
    "        feat_cols = feat_cols_folds[i]\n",
    "\n",
    "        # Training model\n",
    "        cat_model = CatBoostClassifier(**cat_params)\n",
    "        cat_features = np.where(X_kos.dtypes != np.float64)[0]\n",
    "        train_pool = Pool(X_kos, y_kos, cat_features=cat_features)\n",
    "        cat_model.fit(train_pool)\n",
    "\n",
    "        # Record the importance of features and save them only once\n",
    "        if feature_importances is None:\n",
    "            feature_importances = cat_model.get_feature_importance()\n",
    "\n",
    "        # Calculated ROC curve\n",
    "        test_pool = Pool(df_test[feat_cols], cat_features=cat_features)\n",
    "        y_proba = cat_model.predict_proba(test_pool)[:, 1]\n",
    "        fpr, tpr, _ = roc_curve(df_test['y'], y_proba)\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        aucs.append(roc_auc)\n",
    "        tprs.append(np.interp(mean_fpr, fpr, tpr))\n",
    "        tprs[-1][0] = 0.0\n",
    "        \n",
    "        # 绘制每折的ROC曲线\n",
    "        plt.plot(fpr, tpr, lw=2, alpha=0.3, label=f'Fold {i+1} ROC (AUC = {roc_auc:.4f})')\n",
    "\n",
    "    # Plot the ROC curve for each fold\n",
    "    mean_tpr = np.mean(tprs, axis=0)\n",
    "    mean_tpr[-1] = 1.0\n",
    "    mean_auc = auc(mean_fpr, mean_tpr)\n",
    "    plt.plot(mean_fpr, mean_tpr, color='b', lw=2, alpha=0.8, label=f'Mean ROC (AUC = {mean_auc:.4f})')\n",
    "    plt.plot([0, 1], [0, 1], linestyle='--', lw=2, color='r', alpha=0.8)\n",
    "    plt.title('ROC Curves for 5-Fold Cross-Validation', fontsize=14)\n",
    "    plt.xlabel('False Positive Rate', fontsize=12)\n",
    "    plt.ylabel('True Positive Rate', fontsize=12)\n",
    "    plt.legend(loc=\"lower right\", fontsize=10)\n",
    "    plt.grid(True)\n",
    "\n",
    "    # 2. Plot confusion matrix\n",
    "    plt.subplot(2, 2, 2)\n",
    "    # Visualization of the confusion matrix using the last folded test set\n",
    "    y_pred = [1 if x >= 0.5 else 0 for x in y_proba]\n",
    "    cm = confusion_matrix(df_test['y'], y_pred)\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['No', 'Yes'], yticklabels=['No', 'Yes'])\n",
    "    plt.title(f'Confusion Matrix for Last Fold', fontsize=14)\n",
    "    plt.xlabel('Predicted Label', fontsize=12)\n",
    "    plt.ylabel('True Label', fontsize=12)\n",
    "\n",
    "    # 3. Plot feature importance\n",
    "    plt.subplot(2, 2, 3)\n",
    "    sns.barplot(x=feature_importances, y=feat_cols)\n",
    "    plt.title('Feature Importance', fontsize=14)\n",
    "    plt.xlabel('Importance', fontsize=12)\n",
    "    plt.ylabel('Feature', fontsize=12)\n",
    "\n",
    "    # 4. Plot the AUC score as the fold changes\n",
    "    plt.subplot(2, 2, 4)\n",
    "    plt.plot(range(1, k+1), aucs, marker='o')\n",
    "    plt.title('AUC Scores per Fold', fontsize=14)\n",
    "    plt.xlabel('Fold', fontsize=12)\n",
    "    plt.ylabel('AUC Score', fontsize=12)\n",
    "    plt.grid(True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "full_visualization(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f6a364d13925a7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-12T07:05:20.551067Z",
     "start_time": "2024-10-12T07:05:07.941273Z"
    }
   },
   "outputs": [],
   "source": [
    "# Plot top 20 feature importances with values from the provided CatBoost model\n",
    "def plot_top_feature_importances(feature_importances, feat_cols):\n",
    "    # Sort feature importances in descending order\n",
    "    sorted_idx = np.argsort(feature_importances)[::-1][:20]\n",
    "    top_features = np.array(feat_cols)[sorted_idx]\n",
    "    top_importances = feature_importances[sorted_idx]\n",
    "\n",
    "    # Plotting the top 20 features\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.barplot(x=top_importances, y=top_features, palette='coolwarm')\n",
    "    plt.title('Top 20 Feature Importances', fontsize=16, fontweight='bold')\n",
    "    plt.xlabel('Importance', fontsize=14)\n",
    "    plt.ylabel('Feature', fontsize=14)\n",
    "\n",
    "    # Annotating each bar with its value\n",
    "    for index, value in enumerate(top_importances):\n",
    "        plt.text(value + 0.005, index, f'{value:.4f}', va='center', fontsize=12)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# CatBoost training and feature importance extraction\n",
    "def get_feature_importances_and_plot(best_params):\n",
    "    cat_params = {\n",
    "        'eval_metric': 'AUC',\n",
    "        'iterations': 1000,\n",
    "        'depth': int(best_params[0]),\n",
    "        'learning_rate': best_params[1],\n",
    "        'subsample': best_params[2],\n",
    "        'rsm': best_params[3],\n",
    "        'verbose': False\n",
    "    }\n",
    "    \n",
    "    # Use the first fold to train the model and obtain feature importance\n",
    "    X_kos = X_kos_folds[0]\n",
    "    y_kos = y_kos_folds[0]\n",
    "    feat_cols = feat_cols_folds[0]\n",
    "    \n",
    "    cat_model = CatBoostClassifier(**cat_params)\n",
    "    cat_features = np.where(X_kos.dtypes != np.float64)[0]\n",
    "    train_pool = Pool(X_kos, y_kos, cat_features=cat_features)\n",
    "    cat_model.fit(train_pool)\n",
    "    \n",
    "    # Acquired feature importance\n",
    "    feature_importances = cat_model.get_feature_importance()\n",
    "    print(feature_importances)\n",
    "    # Plot the importance of the top 20 features\n",
    "    plot_top_feature_importances(feature_importances, feat_cols)\n",
    "\n",
    "\n",
    "get_feature_importances_and_plot(best_params)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
